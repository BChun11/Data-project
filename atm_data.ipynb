{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "X7W_QnrHCJYx",
        "ViBoglC1CRxs",
        "kG5eEo3zsJuM"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data Analysis \n",
        "\n",
        "#### Section 0: Exploratory Data Analysis\n",
        "#### Section 1: LASSO Models \n",
        "#### Section 2: Ridge Models \n",
        "#### Section 3: ElasticNet Models  \n",
        "#### Section 4: Cross validation across regression regularization models\n",
        "#### Section 5: Neural Network Models\n",
        "#### Section 6: OLS Models (CHOSEN MODEL)"
      ],
      "metadata": {
        "id": "pJgXIOjl_hdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LassoLarsIC\n",
        "from sklearn.pipeline import make_pipeline \n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNetCV\n",
        "from sklearn.linear_model import ElasticNet\n",
        "import math\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.layers.core import Dense \n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import statsmodels.formula.api as smf\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from statsmodels.regression import linear_model\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "\n",
        "from sklearn.linear_model import Ridge, RidgeCV, Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "#warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "sns.set_context('notebook') \n",
        "sns.set_style('ticks')"
      ],
      "metadata": {
        "id": "xH0rM6su_6Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(\"ATM_test.csv\")\n",
        "df_train = pd.read_csv(\"ATM_training.csv\")"
      ],
      "metadata": {
        "id": "oOx7ThZpAQoL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "1bbff6a1-8692-4a86-c259-18a5fdb2cb09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-14ac0e6c27b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ATM_test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ATM_training.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ATM_test.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = df_train.iloc[:,-1]\n",
        "x_train = df_train.iloc[:,0:6]\n",
        "x_test = df_test.iloc[:,0:6]\n",
        "y_test = df_test.iloc[:,-1]"
      ],
      "metadata": {
        "id": "f5DgHBQtBceq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 0: Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "X7W_QnrHCJYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.describe()"
      ],
      "metadata": {
        "id": "3y4ROY-oEb2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['High'].value_counts()"
      ],
      "metadata": {
        "id": "PO_ZH9MKEg7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(df_train)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S8EhabyhEipr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlations = df_train.corr()\n",
        "correlations"
      ],
      "metadata": {
        "id": "ZnPB66dDEl21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corrmat = df_train.corr()\n",
        "hm = sns.heatmap(corrmat, \n",
        "                 cbar=True, \n",
        "                 annot=True, \n",
        "                 square=True, \n",
        "                 fmt='.2f', \n",
        "                 annot_kws={'size': 10}, \n",
        "                 yticklabels=df_train.columns, \n",
        "                 xticklabels=df_train.columns, \n",
        "                 cmap=\"Spectral_r\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "faHsA34bEn6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1: LASSO Models"
      ],
      "metadata": {
        "id": "CnPLnfml_76Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model & Variable Selection"
      ],
      "metadata": {
        "id": "7s_SVAnLtQog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AIC Criterion"
      ],
      "metadata": {
        "id": "qhxCHbCPA1Pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "lasso_lars_ic = make_pipeline(\n",
        "    StandardScaler(), LassoLarsIC(criterion=\"aic\", normalize=True) ).fit(x_train, np.ravel(y_train))\n",
        "fit_time = time.time() - start_time"
      ],
      "metadata": {
        "id": "aYJ03V4_Axyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame( \n",
        "    {\n",
        "        \"alphas\": lasso_lars_ic[-1].alphas_,\n",
        "        \"AIC criterion\": lasso_lars_ic[-1].criterion_,\n",
        "    }\n",
        ").set_index(\"alphas\")\n",
        "alpha_aic = lasso_lars_ic[-1].alpha_"
      ],
      "metadata": {
        "id": "Xm4ifm0rA4k1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BIC Criterion"
      ],
      "metadata": {
        "id": "7bjLJMgvA6LE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_lars_ic.set_params(lassolarsic__criterion=\"bic\").fit(x_train, np.ravel(y_train))\n",
        "results[\"BIC criterion\"] = lasso_lars_ic[-1].criterion_\n",
        "alpha_bic = lasso_lars_ic[-1].alpha_"
      ],
      "metadata": {
        "id": "IXsdETYTA5cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def highlight_min(x):\n",
        "    x_min = x.min()\n",
        "    return [\"font-weight: bold\" if v == x_min else \"\" for v in x]\n",
        "\n",
        "results.style.apply(highlight_min)"
      ],
      "metadata": {
        "id": "FTx_Jv0uA_6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graphing BIC and AIC Values"
      ],
      "metadata": {
        "id": "HZXzXiYcBFRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ax = results.plot()\n",
        "\n",
        "ax.vlines(\n",
        "    alpha_aic,\n",
        "    results[\"AIC criterion\"].min(),\n",
        "    results[\"AIC criterion\"].max(),\n",
        "    label=\"alpha: AIC estimate\",\n",
        "    linestyles=\"--\",\n",
        "    color=\"tab:blue\",\n",
        ")\n",
        "ax.vlines(\n",
        "    alpha_bic,\n",
        "    results[\"BIC criterion\"].min(),\n",
        "    results[\"BIC criterion\"].max(),\n",
        "    label=\"alpha: BIC estimate\",\n",
        "    linestyle=\"--\",\n",
        "    color=\"tab:orange\",\n",
        ")\n",
        "\n",
        "ax.set_xlabel(r\"$\\alpha$\")\n",
        "ax.set_ylabel(\"criterion\")\n",
        "ax.set_xscale(\"log\")\n",
        "ax.legend()\n",
        "_ = ax.set_title(\n",
        "    f\"Information-criterion for model selection (training time {fit_time:.2f}s)\"\n",
        ")"
      ],
      "metadata": {
        "id": "435rkmf_BEZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CV"
      ],
      "metadata": {
        "id": "vDa1ruwWBKh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "model = make_pipeline(StandardScaler(), LassoCV(cv=30)).fit(x_train, np.ravel(y_train))\n",
        "fit_time = time.time() - start_time"
      ],
      "metadata": {
        "id": "Oim9Db9iBMHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_alpha_cv = model[-1].alpha_"
      ],
      "metadata": {
        "id": "MH8Nvcq1B9XC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ymin, ymax = 2300, 3800\n",
        "lasso = model[-1]\n",
        "plt.semilogx(lasso.alphas_, lasso.mse_path_, linestyle=\":\")\n",
        "plt.plot(\n",
        "    lasso.alphas_,\n",
        "    lasso.mse_path_.mean(axis=-1),\n",
        "    color=\"black\",\n",
        "    label=\"Average across the folds\",\n",
        "    linewidth=2,\n",
        ")\n",
        "plt.axvline(lasso.alpha_, linestyle=\"--\", color=\"black\", label=\"alpha: CV estimate\")\n",
        "plt.xlabel(r\"$\\alpha$\")\n",
        "plt.ylabel(\"Mean square error\")\n",
        "plt.legend()\n",
        "_ = plt.title(\n",
        "    f\"Mean square error on each fold: coordinate descent (train time: {fit_time:.2f}s)\"\n",
        ")"
      ],
      "metadata": {
        "id": "c1KYPeeIBUdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alphas = np.linspace(0.001,200,100)\n",
        "lasso = Lasso(max_iter=10000, normalize=True)\n",
        "coefs = []\n",
        "\n",
        "for a in alphas:\n",
        "    lasso.set_params(alpha=a)\n",
        "    lasso.fit(x_train, y_train)\n",
        "    coefs.append(lasso.coef_)\n",
        "ax = plt.gca()\n",
        "\n",
        "ax.plot(alphas, coefs)\n",
        "ax.set_xscale('log')\n",
        "plt.axis('tight')\n",
        "plt.xlabel('alpha')\n",
        "plt.legend(labels=x_train.columns)\n",
        "plt.ylabel('Standardized Coefficients')\n",
        "plt.axvline(model[-1].alpha_, linestyle=\"--\", color=\"black\", label=\"alpha: CV estimate\")\n",
        "plt.title('Lasso coefficients as a function of alpha');"
      ],
      "metadata": {
        "id": "clE0GGJ5BXEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Models"
      ],
      "metadata": {
        "id": "WMmeHYJ2tM3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best CV Model"
      ],
      "metadata": {
        "id": "llABQvtjBrYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lassocv_best = Lasso(alpha=model[-1].alpha_)\n",
        "lassocv_best.fit(x_train, y_train)\n",
        "lassoCV_coef = lassocv_best.coef_\n",
        "lassoCV_MSE = mean_squared_error(y_test, lassocv_best.predict(x_test))"
      ],
      "metadata": {
        "id": "pNDg24vsBXrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(lassoCV_coef, index = x_train.columns).T"
      ],
      "metadata": {
        "id": "obStNKnIB3l9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best AIC Model"
      ],
      "metadata": {
        "id": "MxDsNOnDBs3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lassoaic_best = Lasso(alpha=alpha_aic)\n",
        "lassoaic_best.fit(x_train, y_train)\n",
        "lassoAIC_coef = lassoaic_best.coef_\n",
        "lassoAIC_MSE = mean_squared_error(y_test, lassoaic_best.predict(x_test))"
      ],
      "metadata": {
        "id": "dA93gVedBuio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(lassoAIC_coef, index = x_train.columns).T"
      ],
      "metadata": {
        "id": "huz7nhpWB23X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best BIC Model"
      ],
      "metadata": {
        "id": "sMgb8gnlBxY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lassobic_best = Lasso(alpha=alpha_bic)\n",
        "lassobic_best.fit(x_train, y_train)\n",
        "lassoBIC_coef = lassobic_best.coef_\n",
        "lassoBIC_MSE = mean_squared_error(y_test, lassobic_best.predict(x_test))"
      ],
      "metadata": {
        "id": "P9jIB1cDBwvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(lassoBIC_coef, index = x_train.columns).T"
      ],
      "metadata": {
        "id": "nlvGOcUtCDoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Qiwu-rObbN4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Section 2: Ridge Regression Model"
      ],
      "metadata": {
        "id": "5Vh7FfMJbWbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alphas = np.exp(np.linspace(-10,20,500)) "
      ],
      "metadata": {
        "id": "9KqpbzmXbd5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#use CV to find the best alpha value for the data \n",
        "\n",
        "ridgecv = RidgeCV(alphas = alphas, scoring = 'neg_mean_squared_error', normalize = True)\n",
        "ridgecv.fit(x_train, y_train)\n",
        "ridgecv.alpha_"
      ],
      "metadata": {
        "id": "JDfB9fcNb1hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pass the best alpha value into the ridge regression and fit it\n",
        "\n",
        "ridge = Ridge(alpha = ridgecv.alpha_, normalize = True)\n",
        "ridge.fit(x_train, y_train)\n",
        "\n",
        "mse = mean_squared_error(y_test, ridge.predict(x_test))"
      ],
      "metadata": {
        "id": "lSuOOGmZcP-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(ridge.coef_, index = x_train.columns).T"
      ],
      "metadata": {
        "id": "5GWBWQUob_Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = ridge.predict(x_test)"
      ],
      "metadata": {
        "id": "Mh5U9cqucUCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the module\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# fitting the size of the plot\n",
        "plt.figure(figsize = (15, 8))\n",
        "\n",
        "# plotting the graphs for actual-value and predicted values\n",
        "plt.plot(y_test, label = \"actual-values\")\n",
        "plt.plot(y_pred, label = \"Predicted values\")\n",
        "\n",
        "# showing the plotting of predictive modelling technique\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hb5DU3kwcV5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 3: Elastic Net Models"
      ],
      "metadata": {
        "id": "9vxzK-9ZiECJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dealing with categorical features"
      ],
      "metadata": {
        "id": "P5W1Aez1iuMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.get_dummies(df_train, drop_first=True)\n",
        "test=pd.get_dummies(df_test, drop_first=True)"
      ],
      "metadata": {
        "id": "TOO2s2dwjGjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = ['Withdraw']\n",
        "predictors=[x for x in list(train.columns) if x not in response]\n"
      ],
      "metadata": {
        "id": "5YrAnDiIjT-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elastic Net Model\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Determine shrinkage parameter to choose optimal alpha value: Using cross validation method"
      ],
      "metadata": {
        "id": "gsa7YH6AjcJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train[predictors]\n",
        "y_train = train[response]\n",
        "# Determining optimal alpha value\n",
        "enet_cv = ElasticNetCV(l1_ratio=[0.01,0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.95,0.99], normalize=True)\n",
        "enet_cv.fit(train[predictors], np.ravel(train[response]))\n",
        "enet = ElasticNet(alpha=enet_cv.alpha_, l1_ratio=enet_cv.l1_ratio_)\n",
        "\n",
        "# Fitting the Elastic Net model to the training data\n",
        "enet = enet.fit(x_train, np.ravel(y_train))"
      ],
      "metadata": {
        "id": "zwYKq_1ajehu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "l1_ratio is almost close to 1. Thus, using cross-validation l1 lasso has an overly better performance than l2."
      ],
      "metadata": {
        "id": "ZYSLwT-BjhnI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate Mean squared Error and R2 value for the Elastic Net model"
      ],
      "metadata": {
        "id": "c4zdOADEkf0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = test[predictors]\n",
        "y = test[response]\n",
        "\n",
        "enet_score = enet.score(x, y)\n",
        "predict_y = enet.predict(x)\n",
        "\n",
        "# Mean squared Error of Elastic net model\n",
        "mse = mean_squared_error(y, predict_y)"
      ],
      "metadata": {
        "id": "OgrKaLi7kqQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the Elastic net model predicted values against the actual observed values"
      ],
      "metadata": {
        "id": "W0HsAFLKl4IJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting the size of the plot\n",
        "plt.figure(figsize=(15, 8))\n",
        "y_test = test[response]\n",
        "y_pred = enet.predict(x_test)\n",
        "\n",
        "# plotting the graphs for actual-value and predicted values\n",
        "plt.plot(y_test, label = \"actual-values\")\n",
        "plt.plot(y_pred, label = \"Predicted values\")\n",
        "\n",
        "# showing the plotting of predictive modelling technique\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LlDzHjIJmEFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 4: Cross validation across Regression Regularization models"
      ],
      "metadata": {
        "id": "SB53Cn2QJ3X_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross Validation across Lasso, Ridge and Elastic Net Regression models\n"
      ],
      "metadata": {
        "id": "U7UcUIHyKEcp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suggests which model best performs on the training dataset"
      ],
      "metadata": {
        "id": "M_-3N4xc6O_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use KFold for Cross validator\n",
        "kfold = KFold(10, shuffle=True, random_state=1)\n",
        "\n",
        "# Data frame column and row \n",
        "columns = ['CV MSE']\n",
        "rows = ['Ridge', 'Lasso']\n",
        "\n",
        "regressions = [lassoaic_best, ridge]\n",
        "# Create Data frame that holds the performance on each model\n",
        "results = pd.DataFrame(0.0, columns=columns, index=rows)\n",
        "\n",
        "methods = {k: v for k, v in zip(rows, regressions)}\n",
        "# Compute results for each model\n",
        "keys = ['Ridge', 'Lasso']\n",
        "for k in keys:\n",
        "    scores = cross_val_score(methods[k], x_train, np.ravel(y_train), cv=kfold, scoring = 'neg_mean_squared_error')\n",
        "    results.loc[k] = -1*np.mean(scores)\n",
        "results.round(4)"
      ],
      "metadata": {
        "id": "gqy5xx7zKCNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suggests which model best performs on the test dataset"
      ],
      "metadata": {
        "id": "2WOh16Mc6SkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = test[predictors]\n",
        "y_test = test[response]\n",
        "\n",
        "# Use KFold for Cross validator\n",
        "kfold = KFold(10, shuffle=True, random_state=1)\n",
        "\n",
        "# Data frame column and row \n",
        "columns = ['CV MSE']\n",
        "rows = ['Ridge', 'Lasso']\n",
        "\n",
        "regressions = [lassoaic_best, ridge]\n",
        "# Create Data frame that holds the performance on each model\n",
        "results = pd.DataFrame(0.0, columns=columns, index=rows)\n",
        "\n",
        "methods = {k: v for k, v in zip(rows, regressions)}\n",
        "\n",
        "# Compute results for each model\n",
        "keys = ['Ridge', 'Lasso']\n",
        "for k in keys:\n",
        "    scores = cross_val_score(methods[k], x_test, np.ravel(y_test), cv=kfold, scoring = 'neg_mean_squared_error')\n",
        "    results.loc[k] = -1*np.mean(scores)\n",
        "results.round(4)"
      ],
      "metadata": {
        "id": "mh5DRfB16XBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 5: Neural Network Models"
      ],
      "metadata": {
        "id": "ViBoglC1CRxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "tf.random.set_seed(0)"
      ],
      "metadata": {
        "id": "qZjvzjTqCVBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "fitted_transformer = scaler.fit(x_train)\n",
        "x_train_scaled = fitted_transformer.transform(x_train)\n",
        "\n",
        "fitted_transformer = scaler.fit(x_test)\n",
        "x_test_scaled = fitted_transformer.transform(x_test)\n",
        "\n",
        "fitted_transformer = scaler.fit(y_test)\n",
        "y_test_scaled = fitted_transformer.transform(y_test)\n",
        "\n",
        "fitted_transformer = scaler.fit(y_train)\n",
        "y_train_scaled = fitted_transformer.transform(y_train)"
      ],
      "metadata": {
        "id": "CGVS70HtCnrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Optimal Neural Network Model:\n",
        "Sigmoid Activation\n",
        "\n"
      ],
      "metadata": {
        "id": "vqqT_XIaDCI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''model = Sequential()\n",
        "model.add(Dense(6, input_dim=6, activation='sigmoid'))\n",
        "model.add(Dense(6, activation='sigmoid'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
        "model.summary()\n",
        "history = model.fit(x_train_scaled, y_train_scaled, epochs=250, batch_size=20, verbose=2)\n",
        "mean_squared_error(scaler.inverse_transform(y_test_scaled), scaler.inverse_transform(model.predict(x_test_scaled)))'''"
      ],
      "metadata": {
        "id": "HYIBlbltCqYo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "901c4543-81b6-44de-e04c-1dd9f73d806e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"model = Sequential()\\nmodel.add(Dense(6, input_dim=6, activation='sigmoid'))\\nmodel.add(Dense(6, activation='sigmoid'))\\nmodel.add(Dense(1, activation='linear'))\\nmodel.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\\nmodel.summary()\\nhistory = model.fit(x_train_scaled, y_train_scaled, epochs=250, batch_size=20, verbose=2)\\nmean_squared_error(scaler.inverse_transform(y_test_scaled), scaler.inverse_transform(model.predict(x_test_scaled)))\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''y_pred = model.predict(x_test_scaled)\n",
        "y_pred = scaler.inverse_transform(y_pred)\n",
        "# fitting the size of the plot\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "# plotting the graphs for actual-value and predicted values\n",
        "plt.plot(y_test, label = \"True Values\")\n",
        "plt.plot(y_pred, label = \"Predicted values\")\n",
        "plt.title(\"Neural Network Sigmoid Activation Model True versus Predicted Values of Withdraw Variable from Test Data\")\n",
        "\n",
        "# showing the plotting of predictive modelling technique\n",
        "plt.legend()\n",
        "plt.show()'''"
      ],
      "metadata": {
        "id": "C8iT1V1sC4Ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''plt.plot(history.history['mse'])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Mean Square Error (MSE)\")\n",
        "plt.title(\"MSE Training Evaluation Over Epochs\")\n",
        "plt.show()'''"
      ],
      "metadata": {
        "id": "kPNCqDZKC-Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other models considered\n",
        "\n",
        "*   Tanh Activation with no, one and two hidden layers\n",
        "*   Relu Activation with one and no hidden layers\n",
        "\n"
      ],
      "metadata": {
        "id": "ImQJovFWDMRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''model3 = Sequential()\n",
        "model3.add(Dense(6, input_dim=6, activation='tanh'))\n",
        "model3.add(Dense(6, activation='tanh'))\n",
        "model3.add(Dense(1, activation='linear'))\n",
        "model3.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model3.summary()\n",
        "model3.fit(x_train_scaled, y_train_scaled, epochs=100, batch_size=20, verbose=0)\n",
        "mean_squared_error(scaler.inverse_transform(y_test_scaled), scaler.inverse_transform(model3.predict(x_test_scaled)))'''"
      ],
      "metadata": {
        "id": "TMqNOzuuDLkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''model4 = Sequential()\n",
        "model4.add(Dense(6, input_dim=6, activation='tanh'))\n",
        "model4.add(Dense(1, activation='linear'))\n",
        "model4.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model4.summary()\n",
        "model4.fit(x_train_scaled, y_train_scaled, epochs=100, batch_size=20, verbose=0)\n",
        "mean_squared_error(scaler.inverse_transform(y_test_scaled), scaler.inverse_transform(model4.predict(x_test_scaled)))'''"
      ],
      "metadata": {
        "id": "cX32zve1DtYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''model5 = Sequential()\n",
        "model5.add(Dense(6, input_dim=6, activation='tanh'))\n",
        "model5.add(Dense(6, activation='tanh'))\n",
        "model5.add(Dense(6, activation='tanh'))\n",
        "model5.add(Dense(1, activation='linear'))\n",
        "model5.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model5.summary()\n",
        "model5.fit(x_train_scaled, y_train_scaled, epochs=100, batch_size=20, verbose=0)\n",
        "mean_squared_error(scaler.inverse_transform(y_test_scaled), scaler.inverse_transform(model5.predict(x_test_scaled)))'''"
      ],
      "metadata": {
        "id": "ZMGZl_fBD6ZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''model6 = Sequential()\n",
        "model6.add(Dense(6, input_dim=6, activation='relu'))\n",
        "model6.add(Dense(6, activation='relu'))\n",
        "model6.add(Dense(1, activation='linear'))\n",
        "model6.compile(loss='MSE', optimizer='adam')\n",
        "model6.fit(x_train_scaled, y_train_scaled, epochs=100, batch_size=20, verbose=0)\n",
        "mean_squared_error(scaler.inverse_transform(y_test_scaled), scaler.inverse_transform(model6.predict(x_test_scaled)))'''"
      ],
      "metadata": {
        "id": "vSiPiKbODge3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''model2 = Sequential()\n",
        "model2.add(Dense(6, input_dim=6, activation='relu'))\n",
        "model2.add(Dense(1, activation='linear'))\n",
        "model2.compile(loss='MSE', optimizer='adam')\n",
        "model2.fit(x_train_scaled, y_train_scaled, epochs=100, batch_size=20, verbose=0)\n",
        "mean_squared_error(scaler.inverse_transform(y_test_scaled), scaler.inverse_transform(model2.predict(x_test_scaled)))'''"
      ],
      "metadata": {
        "id": "--9r2B2qEByi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 6: OLS Models (Chosen Model)"
      ],
      "metadata": {
        "id": "kG5eEo3zsJuM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Polynomial Feature Analysis for Interaction Terms"
      ],
      "metadata": {
        "id": "m7zsbSSxscOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_interaction = PolynomialFeatures(6, interaction_only=True, include_bias=False)\n",
        "x_interaction_transformation = x_interaction.fit_transform(x_train)\n",
        "interaction_df = pd.DataFrame(x_interaction_transformation, columns = x_interaction.get_feature_names())\n",
        "interaction_model = linear_model.OLS(y_train, interaction_df).fit()\n",
        "pd.DataFrame(interaction_model.pvalues[interaction_model.pvalues < 0.00001])"
      ],
      "metadata": {
        "id": "Ulo2PtpksT1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best and Chosen Model"
      ],
      "metadata": {
        "id": "Io-DI5Kws0qN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "formula = 'Withdraw ~ Shops*Downtown*ATMs*Weekday*Center + Downtown*ATMs*Weekday*Center + Shops*ATMs*Weekday*Center + Shops*Downtown*Weekday*Center + Shops*Downtown*ATMs*Center + Shops*Downtown*ATMs*Weekday + Shops*Downtown*ATMs + Shops*Downtown*Weekday + Shops*Downtown*Center + Shops*Weekday*Center + Shops*ATMs*Center + Shops*ATMs*Weekday + Downtown*ATMs*Weekday + Downtown*ATMs*Center + Downtown*Weekday*Center + ATMs*Weekday*Center + Downtown*ATMs + Shops*Downtown + Shops*ATMs + Shops*Weekday + Shops*Center + Downtown*Weekday + Downtown*Center + ATMs*Weekday + ATMs*Center + Weekday*Center + High + Center + Weekday + Shops + Downtown + ATMs'"
      ],
      "metadata": {
        "id": "-6BcAYmnspUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm = smf.ols(formula, df_train).fit()"
      ],
      "metadata": {
        "id": "cDWEeKULst5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm.summary()"
      ],
      "metadata": {
        "id": "B8FtTqUasxL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test MSE For Chosen Model"
      ],
      "metadata": {
        "id": "1GKkbwDZeGqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error(y_test, lm.predict(x_test))"
      ],
      "metadata": {
        "id": "oG6KEzeosus9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other models"
      ],
      "metadata": {
        "id": "2eLDHcStsjhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm = smf.ols('Withdraw ~ Shops + Downtown + ATMs + Weekday + Center + High', df_train).fit()\n",
        "formula = 'Withdraw ~ Shops*Downtown*ATMs*Weekday*High + Downtown*ATMs*Weekday*High + Shops*ATMs*Weekday*High + Shops*Downtown*Weekday*High + Shops*Downtown*ATMs*High + Shops*Downtown*ATMs*Weekday + Shops*Downtown*ATMs + Shops*Downtown*Weekday + Shops*Downtown*High + Shops*Weekday*High + Shops*ATMs*High + Shops*ATMs*Weekday + Downtown*ATMs*Weekday + Downtown*ATMs*High + Downtown*Weekday*High + ATMs*Weekday*High + Downtown*ATMs + Shops*Downtown + Shops*ATMs + Shops*Weekday + Shops*High + Downtown*Weekday + Downtown*High + ATMs*Weekday + ATMs*High + Weekday*High + Center + High + Weekday + Shops + Downtown + ATMs'\n",
        "lm = smf.ols(formula, df_train).fit()"
      ],
      "metadata": {
        "id": "xZue7fOlsfvq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}